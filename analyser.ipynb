{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13c74a15-a512-4f17-90c2-b5bf70d2bb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  service  food  \\\n",
      "0                but the staff was so horrible to us        1     0   \n",
      "1  to be completely fair the only redeeming facto...        0     1   \n",
      "2  the food is uniformly exceptional with a very ...        0     1   \n",
      "3  where gabriela personaly greets you and recomm...        1     0   \n",
      "4  for those that go once and dont enjoy it all i...        0     0   \n",
      "\n",
      "   anecdotes/miscellaneous  price  ambience    review  \n",
      "0                        0      0         0  negative  \n",
      "1                        1      0         0   neutral  \n",
      "2                        0      0         0  positive  \n",
      "3                        0      0         0  positive  \n",
      "4                        1      0         0   neutral  \n",
      "Aspect Classification Accuracy: 0.5916749256689792\n",
      "Aspect Classification Hamming Loss: 0.11298315163528246\n",
      "Aspect Classification Precision: 0.8443051201671892\n",
      "Sentiment Analysis Accuracy: 0.6134786917740337\n",
      "Sentiment Analysis Precision: 0.6134786917740337\n",
      "Predicted Aspects: [[1 0 0 0 0]]\n",
      "Predicted Sentiments: ['positive']\n",
      "Predicted Aspect Labels: ['service']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import hamming_loss, accuracy_score, precision_score\n",
    "import re\n",
    "\n",
    "# Load dataset\n",
    "aspects_df = pd.read_csv('semeval2014-1.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(aspects_df.head())\n",
    "\n",
    "# Aspect labels\n",
    "aspect_labels = [\"service\", \"food\", \"anecdotes/miscellaneous\", \"price\", \"ambience\"]\n",
    "\n",
    "# Function to handle contractions and negations\n",
    "def preprocess_text(text):\n",
    "    # Define contractions\n",
    "    contractions = {\n",
    "        \"can't\": \"cannot\",\n",
    "        \"won't\": \"will not\",\n",
    "        \"shan't\": \"shall not\",\n",
    "        \"n't\": \" not\",\n",
    "        \"'re\": \" are\",\n",
    "        \"'s\": \" is\",\n",
    "        \"'d\": \" would\",\n",
    "        \"'ll\": \" will\",\n",
    "        \"'t\": \" not\",\n",
    "        \"'ve\": \" have\",\n",
    "        \"'m\": \" am\"\n",
    "    }\n",
    "\n",
    "    # Replace contractions\n",
    "    for contraction, replacement in contractions.items():\n",
    "        text = re.sub(contraction, replacement, text)\n",
    "\n",
    "    # Handle negations\n",
    "    negations = [\"not\", \"never\", \"no\", \"none\", \"nobody\", \"nothing\", \"neither\", \"nowhere\", \"hardly\", \"scarcely\", \"barely\", \"cannot\"]\n",
    "    text_tokens = text.split()\n",
    "    for i in range(len(text_tokens) - 1):\n",
    "        if text_tokens[i] in negations:\n",
    "            text_tokens[i + 1] = \"NOT_\" + text_tokens[i + 1]\n",
    "    return \" \".join(text_tokens)\n",
    "\n",
    "# Apply preprocessing to text data\n",
    "aspects_df[\"text\"] = aspects_df[\"text\"].apply(preprocess_text)\n",
    "\n",
    "# Extract features and labels for aspect classification\n",
    "X_aspect = aspects_df[\"text\"]\n",
    "y_aspect = np.asarray(aspects_df[aspects_df.columns[1:6]])\n",
    "\n",
    "# Vectorize the text data for aspect classification\n",
    "vectorizer_aspect = TfidfVectorizer(max_features=3000, max_df=0.85)\n",
    "X_aspect_tfidf = vectorizer_aspect.fit_transform(X_aspect)\n",
    "\n",
    "# Split the dataset into training and testing sets for aspect classification\n",
    "X_train_aspect, X_test_aspect, y_train_aspect, y_test_aspect = train_test_split(X_aspect_tfidf, y_aspect, test_size=0.33, random_state=42)\n",
    "\n",
    "# Initialize SVM classifier for aspect classification\n",
    "svm_classifier_aspect = SVC(kernel='linear')  # You can specify different kernels if needed\n",
    "\n",
    "# Wrap SVM classifier in MultiOutputClassifier for multi-label classification\n",
    "multi_label_classifier_aspect = MultiOutputClassifier(svm_classifier_aspect, n_jobs=-1)\n",
    "\n",
    "# Train the classifier for aspect classification\n",
    "multi_label_classifier_aspect.fit(X_train_aspect, y_train_aspect)\n",
    "\n",
    "# Extract features and labels for sentiment analysis\n",
    "X_sentiment = aspects_df[\"text\"]\n",
    "y_sentiment = aspects_df[\"review\"]\n",
    "\n",
    "# Vectorize the text data for sentiment analysis using bag-of-words model\n",
    "vectorizer_sentiment = CountVectorizer(max_features=3000, max_df=0.85)\n",
    "X_sentiment_bow = vectorizer_sentiment.fit_transform(X_sentiment)\n",
    "\n",
    "# Split the dataset into training and testing sets for sentiment analysis\n",
    "X_train_sentiment, X_test_sentiment, y_train_sentiment, y_test_sentiment = train_test_split(X_sentiment_bow, y_sentiment, test_size=0.33, random_state=42)\n",
    "\n",
    "# Initialize SVM classifier for sentiment analysis\n",
    "svm_classifier_sentiment = SVC(kernel='linear')  # You can specify different kernels if needed\n",
    "\n",
    "# Train the classifier for sentiment analysis\n",
    "svm_classifier_sentiment.fit(X_train_sentiment, y_train_sentiment)\n",
    "\n",
    "# Predict and evaluate on the test set for aspect classification\n",
    "predicted_aspect = multi_label_classifier_aspect.predict(X_test_aspect)\n",
    "print(f\"Aspect Classification Accuracy: {accuracy_score(y_test_aspect, predicted_aspect)}\")\n",
    "print(f\"Aspect Classification Hamming Loss: {hamming_loss(y_test_aspect, predicted_aspect)}\")\n",
    "print(f\"Aspect Classification Precision: {precision_score(y_test_aspect, predicted_aspect, average='micro')}\")\n",
    "\n",
    "# Predict and evaluate on the test set for sentiment analysis\n",
    "predicted_sentiment = svm_classifier_sentiment.predict(X_test_sentiment)\n",
    "print(f\"Sentiment Analysis Accuracy: {accuracy_score(y_test_sentiment, predicted_sentiment)}\")\n",
    "print(f\"Sentiment Analysis Precision: {precision_score(y_test_sentiment, predicted_sentiment, average='micro', zero_division=1)}\")\n",
    "\n",
    "# Function to predict aspects and sentiment for new sentences\n",
    "def predict_aspects_and_sentiment(new_sentences):\n",
    "    # Apply preprocessing to new sentences\n",
    "    new_sentences = [preprocess_text(sentence) for sentence in new_sentences]\n",
    "\n",
    "    new_sentences_aspect_tfidf = vectorizer_aspect.transform(new_sentences)\n",
    "    predicted_aspects = multi_label_classifier_aspect.predict(new_sentences_aspect_tfidf)\n",
    "    \n",
    "    new_sentences_sentiment_bow = vectorizer_sentiment.transform(new_sentences)\n",
    "    predicted_sentiments = svm_classifier_sentiment.predict(new_sentences_sentiment_bow)\n",
    "    \n",
    "    # Convert numerical predictions to aspect labels\n",
    "    predicted_aspect_labels = []\n",
    "    for aspects in predicted_aspects:\n",
    "        labels = [aspect_labels[i] for i, val in enumerate(aspects) if val == 1]\n",
    "        predicted_aspect_labels.append(\"|\".join(labels))\n",
    "    \n",
    "    return predicted_aspects, predicted_sentiments, predicted_aspect_labels\n",
    "\n",
    "# Example usage\n",
    "new_sentences = [\"the service was too good\"]\n",
    "predicted_aspects, predicted_sentiments, predicted_aspect_labels = predict_aspects_and_sentiment(new_sentences)\n",
    "print(f\"Predicted Aspects: {predicted_aspects}\")\n",
    "print(f\"Predicted Sentiments: {predicted_sentiments}\")\n",
    "print(f\"Predicted Aspect Labels: {predicted_aspect_labels}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513c995f-66d9-4863-bdee-c38aa0495245",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
